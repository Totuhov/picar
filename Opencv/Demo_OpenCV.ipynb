{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurzer Überblick über ausgewählte Funktionen in OpenCV\n",
    "\n",
    "Tutorial mit Überblick über Funktionen: \n",
    "\n",
    "[https://docs.opencv.org/3.4/d6/d00/tutorial_py_root.html](https://docs.opencv.org/3.4/d6/d00/tutorial_py_root.html) (Schwerpunkte Core Operations, Image Processing in OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bilder laden und anzeigen\n",
    "`cv.imread, cv.imwrite, cv.imshow, cv.waitkey, cv.destroyWindows, matplotlib.imshow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden eines Bildes\n",
    "pfile='squirrel.jfif'\n",
    "img = cv.imread(pfile) # Gibt einen Numpy-Array zurück mit den Farbkanälen (Blau,Grün,Rot)\n",
    "print(type(img))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern eines Bildes\n",
    "cv.imwrite('squirrel.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige in einem Fenster mittels OpenCV\n",
    "w=\"Display window (press q to quit)\"\n",
    "cv.imshow(w,img) # \n",
    "k = cv.waitKey(0)\n",
    "if k == ord(\"q\"):\n",
    "    cv.destroyWindow(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Anzeige mit matplotlib\n",
    "# \n",
    "import matplotlib.pylab as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img) # Erwartet die Farbkanäle in der Reihenfolge Rot,Grün,Blau\n",
    "plt.xlabel('BRG-Bild dargestellt als RGB')\n",
    "plt.subplot(122)\n",
    "img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB) # Ändern der Farbkanäle BGR->RGB\n",
    "plt.imshow(img_rgb)\n",
    "plt.xlabel('korrekte Darstellung der Farbkanäle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Anzeige mit PIL\n",
    "from PIL import Image\n",
    "image_rgb=Image.fromarray(img_rgb) #Erwartet RGB\n",
    "print(image_rgb.size,image_rgb.mode)\n",
    "display(image_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung eines Graustufen bildes\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "print(img_gray.shape) # Array ist nun nur 2-dimensional\n",
    "plt.imshow(img_gray,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Farbkanäle\n",
    "`cv.split, cv.merge, cv.cvtColor, cv.putText`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  - Zerlegen der Farbkanäle in 3 Numpy-Arrays\n",
    "`cv.split, cv.merge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zerlegen in einzelne Farbkanäle \n",
    "r,g,b = cv.split(img_rgb)\n",
    "\n",
    "# Beispielhaft Darstellung\n",
    "print(img_rgb.shape[:2])\n",
    "zeros = np.zeros(img_rgb.shape[:2], dtype=\"uint8\")\n",
    "print(zeros.shape)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(141)\n",
    "plt.imshow(img_rgb)\n",
    "plt.subplot(142)\n",
    "plt.imshow(cv.merge([r, zeros, zeros])) # Zusammenführen einzelnen Farbkanäle\n",
    "plt.subplot(143)\n",
    "plt.imshow(cv.merge([zeros, g, zeros]))\n",
    "plt.subplot(144)\n",
    "plt.imshow(cv.merge([zeros, zeros, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Konvertieren in anderen Farbraum: BGR->HSV\n",
    "`cv.cvtColor, cv.putText`\n",
    "\n",
    "Im Farbraum HSV kann das Filtern nach eine bestimmten Farbe einfacher sein!\n",
    "(siehe auch [https://de.wikipedia.org/wiki/HSV-Farbraum](https://de.wikipedia.org/wiki/HSV-Farbraum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ändern des Farbraums RGB->HSV\n",
    "img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "# Fügt Text in Blau hinzu\n",
    "cv.putText(img_hsv, \n",
    "        text = 'Beispielbild',\n",
    "        org=(10,175), # Position\n",
    "        fontFace= cv.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale = .8, # Font size\n",
    "        color = (120,255,255), # Color in hsv\n",
    "        thickness = 2)\n",
    "\n",
    "h,v,s = cv.split(img_hsv) # Aufteilen der Farbkanäle\n",
    "# h Farbwert (hue)\n",
    "# s Farbsättigung (saturation)\n",
    "# v Hellwert (value)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(141)\n",
    "plt.imshow(cv.cvtColor(img_hsv, cv.COLOR_HSV2RGB))\n",
    "plt.xlabel('Original mit blauem Text')\n",
    "plt.subplot(142)\n",
    "plt.imshow(cv.cvtColor(cv.merge([h, zeros+255, zeros+255]), cv.COLOR_HSV2RGB))\n",
    "plt.xlabel('Farbwert mit max. Farbsättigung und Hellwert')\n",
    "plt.subplot(143)\n",
    "plt.imshow(v,cmap='gray')\n",
    "plt.xlabel('Farbsättigung in Graustufen')\n",
    "plt.subplot(144)\n",
    "plt.imshow(s,cmap='gray')\n",
    "plt.xlabel('Hellwert in Graustufen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen einer Farbmaske\n",
    "`cv.inRange`, `cv.threshold`\n",
    "\n",
    "Die Maske stellt alle Bildpunkte, welche ein Filterkriterium bzgl. der Farbe erfüllen z.B. weiß dar. Es können Strukturen eines bestimmten Farbbereichs erfasst werden. Die Maske selbst stellt ebenfalls ein Bild dar!\n",
    "\n",
    "[https://docs.opencv.org/3.4/da/d97/tutorial_threshold_inRange.html](https://docs.opencv.org/3.4/da/d97/tutorial_threshold_inRange.html)\n",
    "\n",
    "[https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ober- und Untergrenze für Farbfiltern\n",
    "lower = np.array([120, 0, 0])\n",
    "upper = np.array([120, 255, 255])\n",
    "mask = cv.inRange(img_hsv, lower, upper) # mask ist Numpy-Array\n",
    "lower = np.array([0, 0, 0])\n",
    "upper = np.array([12, 255, 255])\n",
    "mask2 = cv.inRange(img_hsv, lower, upper) # mask ist Numpy-Array\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(mask2,cmap='gray')\n",
    "plt.xlabel('Schwarz-Weiß-Bild für \"rötlich\"')\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask,cmap='gray')\n",
    "plt.xlabel('Schwarz-Weiß-Bild für Blau (hue=120)')\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Für Graustufen\n",
    "threshold=100\n",
    "ret,img_th = cv.threshold(img_gray,threshold,1,cv.THRESH_BINARY)   # gibt threshold und Resultat zurück\n",
    "ret,img_th2 = cv.threshold(img_gray,threshold,1,cv.THRESH_BINARY_INV) \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(141)\n",
    "plt.imshow(img_rgb)\n",
    "plt.xlabel('originales Farbbild')\n",
    "plt.subplot(142)\n",
    "plt.imshow(img_gray,cmap='gray')\n",
    "plt.xlabel('Bild in Graustufen')\n",
    "plt.subplot(143)\n",
    "plt.imshow(img_th,cmap='gray')\n",
    "plt.xlabel('Mask mit threshold '+str(threshold))\n",
    "plt.subplot(144)\n",
    "plt.imshow(img_th2,cmap='gray')\n",
    "plt.xlabel('invertierte Mask mit threshold '+str(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glätten (smoothing)\n",
    "`cv.blur, cv.addWeighted`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glätten\n",
    "img_blur= cv.blur(img_rgb,(10,10))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_rgb)\n",
    "plt.xlabel('Originalbild')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_blur)\n",
    "plt.xlabel('geglättetes Bild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schärfen: durch Abzug des geglätteten Bild vom Original\n",
    "img_blur2= cv.blur(img_rgb,(10,10))\n",
    "img_sharp = cv.addWeighted(img_rgb,6,img_blur,-5,0)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_rgb)\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_sharp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kantenerkennung mit Canny-Edge-Detection\n",
    "`cv.Canny(image,minVal,maxVal)`\n",
    "\n",
    "Einer der verbreitesten und bewährtesten Algorithmen zur Kantenerkennung ist der Canny-Algorithmus [https://de.wikipedia.org/wiki/Canny-Algorithmus](https://de.wikipedia.org/wiki/Canny-Algorithmus). Dieser Algorithmus besitzt zwei wichtige Paramter `minVal`und `maxVal`. Eine Kante entsteht durch einen hohen Kontrast im Bild. Je höher dieser Kontrast desto höher die Kantenstärke an diesem Bildpunkt. Alle Punkte deren Kantenstärke größer ist als `maxVal` werden als \"sichere\" Kante erkannt. Alle Punkte deren Kantenstärke kleiner ist als `minVal`werden nicht als Kante erkannt. Alle Werte zwischen `minVal`und `maxVal` werden nur als Kante erkannt, wenn diese mit über andere Kanten mit einer\"sicheren\" Kante verbunden sind. (Glätten reduziert die Kantenstärke!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxVal=250\n",
    "minVal=20\n",
    "img_c1 = cv.Canny(img_gray,maxVal,maxVal)\n",
    "img_c2 = cv.Canny(img_gray,minVal,maxVal)\n",
    "\n",
    "# Beispiel:\n",
    "zeros = np.zeros(img_rgb.shape[:2], dtype=\"uint8\")\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img_gray,cmap='gray')\n",
    "plt.xlabel('Original in Graustufen')\n",
    "plt.subplot(132)\n",
    "img_c1_color = cv.merge([img_c1,img_c1,zeros])\n",
    "plt.imshow(img_c1_color)#,cmap='gray')\n",
    "plt.xlabel('Kanten mit Stärke > maxVal')\n",
    "plt.subplot(133)\n",
    "img_c2_color = cv.merge([zeros,zeros,img_c2])\n",
    "_,mask=cv.threshold(img_c1,200,255,cv.THRESH_BINARY_INV)\n",
    "img_both = cv.add(cv.bitwise_or(img_c1_color,img_c2_color,mask = mask),img_c1_color)\n",
    "plt.imshow(img_both,cmap='gray')\n",
    "plt.xlabel('Kanten mit Stärke > min Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile2='street.jpg'\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.open(pfile)\n",
    "print(img.format,img.size,img.mode)\n",
    "\n",
    "image = cv.imread(pfile2)\n",
    "image_blur= cv.blur(image,(8,8))\n",
    "\n",
    "lower = np.array([240, 240, 240])\n",
    "upper = np.array([255, 255, 255])\n",
    "image_mask = cv.inRange(image, lower, upper)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(421)\n",
    "plt.xlabel('Originalbild')\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(422)\n",
    "plt.xlabel('Canny-Edge von Originalbild')\n",
    "plt.imshow(cv.Canny(image,440,450),cmap='gray')\n",
    "\n",
    "plt.subplot(423)\n",
    "plt.xlabel('Originalbild geglättet')\n",
    "plt.imshow(image_blur,cmap='gray')\n",
    "\n",
    "plt.subplot(424)\n",
    "plt.xlabel('Canny-Edge von Originalbild geglättet')\n",
    "plt.imshow(cv.Canny(image_blur,100,150),cmap='gray')\n",
    "\n",
    "plt.subplot(425)\n",
    "plt.xlabel('Originalbild Maske weiß')\n",
    "plt.imshow(image_mask,cmap='gray')\n",
    "\n",
    "plt.subplot(426)\n",
    "image_edges = cv.Canny(image_mask,440,450)\n",
    "plt.xlabel('Canny-Edge von Originalbild Maske weiß')\n",
    "plt.imshow(image_edges,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erkennung von Geraden mittels Hough-Transformation\n",
    "`cv.HoughLines(image_mask, rho, angle, min_threshold)`,\n",
    "\n",
    "Die Hogh-Transformation dient u.a. zur Erkennung von Gerade in Schwarz-Weiß-Bilder z.b. nach einer Kantenerkennung.\n",
    "Vereinfacht betrachte wird überprüft wie viele Kantenpunkte auf einer poteniellen Gerade liegen (`min_threshold`).\n",
    "\n",
    "[https://de.wikipedia.org/wiki/Hough-Transformation](https://de.wikipedia.org/wiki/Hough-Transformation)\n",
    "\n",
    "OpenCV implementiert zwei Versionen der Hough-Transformation - die klassische und die probabilistische.\n",
    "- Die klassische Hough-Transformation gibt die Paramter \"rho\" und \"angle\" zurück, welche in Gerade umgerechnet werden müssen (siehe Beispielcode).\n",
    "- Die probabilistische Hough-Transformation gibt Liniensegment zurück. Diese Stellen den Anfangs- und den Endpunkt der Linien dar.\n",
    "\n",
    "[https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html](https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassische Hough-Transformation\n",
    "image_mask = cv.inRange(image, lower, upper)\n",
    "rho = 1  # distance precision in pixel, i.e. 1 pixel\n",
    "angle = np.pi / 180  # angular precision in radian, i.e. 1 degree\n",
    "min_threshold = 10  # minimal of votes, Je geringer Min_threshold, dest mehr Geraden werden erkannt.\n",
    "\n",
    "parameter_mask = cv.HoughLines(image_mask, rho, angle, min_threshold)\n",
    "print(parameter_mask.shape)\n",
    "parameter_mask[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(parameter_mask,img):\n",
    "    img2 = img.copy()\n",
    "    img2 = cv.cvtColor(img2, cv.COLOR_GRAY2RGB)\n",
    "    for line in parameter_mask:\n",
    "        rho,theta = line[0]\n",
    "        a = -np.cos(theta)/np.sin(theta) # Anstieg der Gerade\n",
    "        b = rho/np.sin(theta)            # Absolutglied/Intercept/Schnittpunkt mit der y-Achse\n",
    "        x1 = 0\n",
    "        y1 = int(b)\n",
    "        x2 = 1000\n",
    "        y2 = int(a*1000+b)\n",
    "        #print(x1,x2,y1,y2)\n",
    "        img2=cv.line(img2,(x1,y1),(x2,y2),(200,100,100),1) # adds a line to an image\n",
    "        cv.putText(img2, \n",
    "            text = 'erkannte Geraden',\n",
    "            org=(10,190), # Position\n",
    "            fontFace= cv.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale = .8, # Font size\n",
    "            color = (120,255,255), # Color in hsv\n",
    "            thickness = 2)\n",
    "    return img2\n",
    "        \n",
    "image_mask = cv.inRange(image, lower, upper)\n",
    "rho = 1  # distance precision in pixel, i.e. 1 pixel\n",
    "angle = np.pi / 180  # angular precision in radian, i.e. 1 degree\n",
    "min_threshold = 65  # minimal of votes\n",
    "parameter_mask = cv.HoughLines(image_mask, rho, angle, min_threshold)\n",
    "print('len line segs:',len(parameter_mask))\n",
    "image_mask_ls=draw_lines(parameter_mask,image_mask)\n",
    "\n",
    "image_edges = cv.Canny(image_mask,200,400)\n",
    "parameter_edges = cv.HoughLines(image_edges, rho, angle, min_threshold)\n",
    "print('len line segs:',len(parameter_edges))\n",
    "image_edges_ls=draw_lines(parameter_edges,image_edges)\n",
    "\n",
    "plt.figure(figsize=(12,15))\n",
    "plt.subplot(421)\n",
    "plt.imshow(image)\n",
    "plt.xlabel('Originalbild')\n",
    "plt.subplot(423)\n",
    "plt.imshow(image_mask,cmap='gray')\n",
    "plt.xlabel('Bild nach Filtern weißer Farbtöne')\n",
    "plt.subplot(424)\n",
    "plt.imshow(image_mask_ls,cmap='gray')\n",
    "plt.xlabel('Hough-Transformation von Bild links')\n",
    "plt.subplot(425)\n",
    "plt.imshow(image_edges,cmap='gray')\n",
    "plt.xlabel('Bild nach Filtern weißer Farbtöne + Kantenerkennung')\n",
    "plt.subplot(426)\n",
    "plt.imshow(image_edges_ls,cmap='gray')\n",
    "plt.xlabel('Hough-Transformation von Bild links')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistische Hough-Transformation\n",
    "image = cv.imread(pfile2)\n",
    "image_mask = cv.inRange(image, lower, upper)\n",
    "image_edges = cv.Canny(image_mask,200,400)\n",
    "rho = 1              # distance precision in pixel, i.e. 1 pixel\n",
    "angle = np.pi / 180  # angular precision in radian, i.e. 1 degree\n",
    "min_threshold = 10   # in etwas Anzal der Punkt auf der Geraden. Je geringer Min_threshold, desto mehr Geraden werden erkannt.\n",
    "minLineLength = 8    # Minimale Linienlänge\n",
    "maxLineGap = 4       # Maximale Anzahl von Lücken in der Linie\n",
    "\n",
    "line_segments = cv.HoughLinesP(image_mask, rho, angle, min_threshold, np.array([]), minLineLength=minLineLength, maxLineGap=maxLineGap)\n",
    "print(line_segments.shape)\n",
    "# Elemente stellen Punkte des Liniensegmentes dar (x1,y1,x2,y2)\n",
    "line_segments[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line_segments(line_segments,img):\n",
    "    img2 = img.copy()\n",
    "    img2 = cv.cvtColor(img2, cv.COLOR_GRAY2RGB)\n",
    "    for line in line_segments:\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        cv.line(img2,(x1,y1),(x2,y2),(0,0,255),4)\n",
    "    return img2\n",
    "\n",
    "rho = 1              # distance precision in pixel, i.e. 1 pixel\n",
    "angle = np.pi / 180  # angular precision in radian, i.e. 1 degree\n",
    "min_threshold = 10   # in etwas Anzal der Punkt auf der Geraden. Je geringer Min_threshold, dest mehr Geraden werden erkannt.\n",
    "minLineLength = 8    # Minimale Linienlänge\n",
    "maxLineGap = 4       # Maximale Anzahl von Lücken in der Linie\n",
    "\n",
    "line_segments = cv.HoughLinesP(image_edges, rho, angle, min_threshold, np.array([]), minLineLength=minLineLength, maxLineGap=maxLineGap)\n",
    "image_edges_ls = draw_line_segments(line_segments,image_edges)\n",
    "print('Anzahl der Liniensegmente Parametersatz 1:',len(line_segments))\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(image_edges,cmap='gray')\n",
    "plt.xlabel('Erkannte Kanten')\n",
    "plt.subplot(223)\n",
    "plt.imshow(image_edges_ls)\n",
    "plt.xlabel('prob. HT mit Parametersatz 1')\n",
    "\n",
    "min_threshold = 100   # in etwas Anzal der Punkt auf der Geraden. Je geringer Min_threshold, dest mehr Geraden werden erkannt.\n",
    "minLineLength = 100   # Minimale Linienlänge\n",
    "maxLineGap = 10     # Maximale Anzahl von Lücken in der Linie\n",
    "line_segments2 = cv.HoughLinesP(image_edges, rho, angle, min_threshold, np.array([]), minLineLength=minLineLength, maxLineGap=maxLineGap)\n",
    "image_edges_ls2 = draw_line_segments(line_segments2,image_edges)\n",
    "print('Anzahl der Liniensegmente Parametersatz 2:',len(line_segments2))\n",
    "plt.subplot(224)\n",
    "plt.imshow(image_edges_ls2)\n",
    "plt.xlabel('prob. HT mit Parametersatz 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spiegeln\n",
    "`cv.flip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_flip= cv.flip(img_rgb,1)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_rgb)\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_flip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blenden\n",
    "`cv.addWeighted`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blended = cv.addWeighted(img_flip,.7,img_rgb,.3,0)\n",
    "plt.imshow(img_blended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling\n",
    "`cv.resize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_rgb.shape)\n",
    "height, width, _ = img_rgb.shape\n",
    "img_small = cv.resize(img_rgb,(65, 50), interpolation = cv.INTER_CUBIC)\n",
    "print(img_small.shape)\n",
    "plt.imshow(img_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video Capturing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Einfaches Beispiel\n",
    "`cv.VideoCapture, isOpened, cap.read`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "def draw_line_segments(line_segments,img):\n",
    "    img2 = img.copy()\n",
    "    #img2 = cv.cvtColor(img2, cv.COLOR_GRAY2RGB)\n",
    "    if line_segments is not None: # Könnte None sein, wenn Hough keine Linie erkennt!\n",
    "        for line in line_segments:\n",
    "            x1,y1,x2,y2 = line[0]\n",
    "            cv.line(img2,(x1,y1),(x2,y2),(255,0,0),1)\n",
    "    return img2\n",
    "\n",
    "# Erstellen eines Objektes für den Kamerazugriff\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "# Schleife für Video Capturing\n",
    "while True:\n",
    "    # Abfrage eines Frames\n",
    "    ret, frame = cap.read()\n",
    "    height, width, _ = frame.shape\n",
    "    frame = cv.resize(frame,(int(width*2/3), int(height*2/3)), interpolation = cv.INTER_CUBIC)\n",
    "    # Wenn ret == TRUE, so war Abfrage erfolgreich\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Bildmanipulation ----------\n",
    "    frame_to_display = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # ---------------------------\n",
    "    # Display des Frames\n",
    "    cv.imshow(\"Display window (press q to quit)\", frame_to_display)\n",
    "    # Ende bei Drücken der Taste q\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# Kamera-Objekt muss \"released\" werden, um \"später\" ein neues Kamera-Objekt erstellen zu können!!!\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demo: Glätten, Canny-Kantenerkennung, Hough-Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "def draw_line_segments(line_segments,img):\n",
    "    img2 = img.copy()\n",
    "    #img2 = cv.cvtColor(img2, cv.COLOR_GRAY2RGB)\n",
    "    if line_segments is not None: # Könnte None sein, wenn Hough keine Linie erkennt!\n",
    "        for line in line_segments:\n",
    "            x1,y1,x2,y2 = line[0]\n",
    "            cv.line(img2,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "    return img2\n",
    "\n",
    "# Erstellen eines Objektes für den Kamerazugriff\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "# Parameter canny\n",
    "maxVal=150\n",
    "minVal=50\n",
    "# Parameter Hough\n",
    "rho = 1              # distance precision in pixel, i.e. 1 pixel\n",
    "angle = np.pi / 180  # angular precision in radian, i.e. 1 degree\n",
    "min_threshold = 70   # in etwas Anzal der Punkt auf der Geraden. Je geringer Min_threshold, dest mehr Geraden werden erkannt.\n",
    "minLineLength = 30   # Minimale Linienlänge\n",
    "maxLineGap = 10       # Maximale Anzahl von Lücken in der Linie\n",
    "# Parameter Test\n",
    "f = cv.FONT_HERSHEY_SIMPLEX\n",
    "c = (0,255,255)\n",
    "\n",
    "# Schleife für Video Capturing\n",
    "while True:\n",
    "    # Abfrage eines Frames\n",
    "    ret, frame = cap.read()\n",
    "    height, width, _ = frame.shape\n",
    "    frame = cv.resize(frame,(int(width*2/3), int(height*2/3)), interpolation = cv.INTER_CUBIC)\n",
    "    # Wenn ret == TRUE, so war Abfrage erfolgreich\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Bildmanipulation ----------\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    frame_canny = cv.Canny(frame_gray,maxVal,maxVal)\n",
    "    line_segments = cv.HoughLinesP(frame_canny, rho, angle, min_threshold, np.array([]), minLineLength=minLineLength, maxLineGap=maxLineGap)\n",
    "    frame_ls = draw_line_segments(line_segments,frame)\n",
    "    frame_to_display = np.hstack((frame,frame_ls)) # Numpy-Operationen sind auch möglich!\n",
    "\n",
    "    frame_gray_blurred=cv.blur(frame_gray,(5,5))\n",
    "    frame_to_display_additional = np.hstack((frame_gray_blurred,frame_canny))\n",
    "    frame_to_display_additional = cv.cvtColor(frame_to_display_additional, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "    frame_to_display_final = np.vstack((frame_to_display,frame_to_display_additional))\n",
    "    cv.putText(frame_to_display_final, text = 'Original', org=(10,303), fontFace= f,fontScale = .5, color = c, thickness = 1)\n",
    "    cv.putText(frame_to_display_final, text = 'Graustufen mit Smoothing', org=(10,616), fontFace= f,fontScale = .5, color = c, thickness = 1)\n",
    "    cv.putText(frame_to_display_final, text = 'Hough-Liniensegmente', org=(445,303), fontFace= f,fontScale = .5, color = c, thickness = 1)\n",
    "    cv.putText(frame_to_display_final, text = 'Canny-Kantenerkennung', org=(445,616), fontFace= f,fontScale = .5, color = c, thickness = 1)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Alternative:\n",
    "    # frame_to_display = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # ---------------------------\n",
    "    # Display des Frames\n",
    "    cv.imshow(\"Display window (press q to quit)\", frame_to_display_final)\n",
    "    # Ende bei Drücken der Taste q\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# Kamera-Objekt muss \"released\" werden, um \"später\" ein neues Kamera-Objekt erstellen zu können!!!\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demo: Farbfilter HSV-Farbraum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def hsv_helper(img):\n",
    "    def nothing(x):\n",
    "        pass\n",
    "    # Create a window\n",
    "    window_id='Press q to quit'\n",
    "    cv2.namedWindow(window_id)\n",
    "    # create trackbars for color change\n",
    "    cv2.createTrackbar('HMin',window_id,0,255,nothing) # Hue is from 0-179 for Opencv\n",
    "    cv2.createTrackbar('SMin',window_id,0,255,nothing)\n",
    "    cv2.createTrackbar('VMin',window_id,0,255,nothing)\n",
    "    cv2.createTrackbar('HMax',window_id,0,255,nothing)\n",
    "    cv2.createTrackbar('SMax',window_id,0,255,nothing)\n",
    "    cv2.createTrackbar('VMax',window_id,0,255,nothing)\n",
    "    # Set default value for MAX HSV trackbars.\n",
    "    cv2.setTrackbarPos('HMax', window_id, 255)\n",
    "    cv2.setTrackbarPos('SMax', window_id, 255)\n",
    "    cv2.setTrackbarPos('VMax', window_id, 255)\n",
    "    # Initialize to check if HSV min/max value changes\n",
    "    hMin = sMin = vMin = hMax = sMax = vMax = 0\n",
    "\n",
    "    output = img\n",
    "    while(1):\n",
    "        # get current positions of all trackbars\n",
    "        hMin = cv2.getTrackbarPos('HMin',window_id)\n",
    "        sMin = cv2.getTrackbarPos('SMin',window_id)\n",
    "        vMin = cv2.getTrackbarPos('VMin',window_id)\n",
    "        hMax = cv2.getTrackbarPos('HMax',window_id)\n",
    "        sMax = cv2.getTrackbarPos('SMax',window_id)\n",
    "        vMax = cv2.getTrackbarPos('VMax',window_id)\n",
    "        # Set minimum and max HSV values to display\n",
    "        lower = np.array([hMin, sMin, vMin])\n",
    "        upper = np.array([hMax, sMax, vMax])\n",
    "        # Create HSV Image and threshold into a range.\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "        output = cv2.bitwise_and(img,img, mask= mask)\n",
    "        cv2.imshow(window_id,output)\n",
    "        if cv2.waitKey(30) == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "pfile='squirrel.jfif'\n",
    "img = cv2.imread(pfile)\n",
    "hsv_helper(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo: Filtern Graustufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def graylevel_helper(img):\n",
    "    def nothing(x):\n",
    "        pass\n",
    "    # Create a window\n",
    "    window_id='Press q to quit'\n",
    "    cv2.namedWindow(window_id)\n",
    "    # create trackbars for color change\n",
    "    cv2.createTrackbar('Max',window_id,0,255,nothing) # Hue is from 0-179 for Opencv\n",
    "    cv2.createTrackbar('Min',window_id,0,255,nothing)\n",
    "    # Set default value for MAX HSV trackbars.\n",
    "    cv2.setTrackbarPos('Max', window_id, 255)\n",
    "    # Initialize to check if HSV min/max value changes\n",
    "    Min = Max = 0\n",
    "    output = img\n",
    "    while(1):\n",
    "\n",
    "        # get current positions of all trackbars\n",
    "        Min = cv2.getTrackbarPos('Min',window_id)\n",
    "        Max = cv2.getTrackbarPos('Max',window_id)\n",
    "\n",
    "        # Set minimum and max HSV values to display\n",
    "        lower = np.array([Min])\n",
    "        upper = np.array([Max])\n",
    "\n",
    "        # Create HSV Image and threshold into a range.\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        mask = cv2.inRange(img_gray, lower, upper)\n",
    "        img_mask = cv2.bitwise_and(img,img, mask= mask)\n",
    "        img_gray_mask = cv2.bitwise_and(img_gray,img_gray, mask = mask)\n",
    "        img_gray_mask_cs = cv2.cvtColor(img_gray_mask,cv2.COLOR_GRAY2BGR)\n",
    "        mask_cs = cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "        output = np.vstack((img_gray_mask_cs,img_mask,mask_cs))\n",
    "        cv2.imshow(window_id,output)\n",
    "        if cv2.waitKey(30) == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "pfile='squirrel.jfif'\n",
    "img = cv2.imread(pfile)\n",
    "graylevel_helper(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0beb15f1d6c09e36588894b2b4870f2131c47961a4b3f35558d97ea92d9ea3de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
